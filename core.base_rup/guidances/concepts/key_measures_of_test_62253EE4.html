<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" lang="ru" xml:lang="ru">
<head>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Концепция: Ключевые характеристики тестов</title>
<meta content="Concept" name="uma.type">
<meta content="key_measures_of_test" name="uma.name">
<meta content="Ключевые характеристики тестов" name="uma.presentationName">
<meta name="element_type" content="concept">
<meta content="description" name="filetype">
<meta name="role" content="">
<link type="text/css" href="./../../../css/default.css" rel="StyleSheet">
<script language="JavaScript" type="text/javascript" src="./../../../scripts/ContentPageResource.js"></script><script language="JavaScript" type="text/javascript" src="./../../../scripts/ContentPageSection.js"></script><script language="JavaScript" type="text/javascript" src="./../../../scripts/ContentPageSubSection.js"></script><script language="JavaScript" type="text/javascript" src="./../../../scripts/ContentPageToolbar.js"></script><script language="JavaScript" type="text/javascript" src="./../../../scripts/contentPage.js"></script><script language="JavaScript" type="text/javascript">
					var backPath = './../../../';
					var imgPath = './../../../images/';
					var nodeInfo=[{view: "view:_MC6wMN7FEdm8G6yT7-Wdqw", path: ["_MC6wMN7FEdm8G6yT7-Wdqw", "_yd3EzdnmEdmO6L4XMImrsA", "5.312818155786224E-305"]}, {view: "view:_bbrmwN7BEdmsEI4YDGX2ag", path: ["_bbrmwN7BEdmsEI4YDGX2ag", "_jD8dUAIbEdqEutyfYo0quQ", "_vzRNgDIcEdqDs_9ORT1Rig", "5.312818155786224E-305"]}, {view: "view:_bbrmwN7BEdmsEI4YDGX2ag", path: ["_bbrmwN7BEdmsEI4YDGX2ag", "_kC0pcN7GEdm8G6yT7-Wdqw", "_yd3EzdnmEdmO6L4XMImrsA", "5.312818155786224E-305"]}, {view: "view:_bbrmwN7BEdmsEI4YDGX2ag", path: ["_bbrmwN7BEdmsEI4YDGX2ag", "_mp7z0DIDEdqwaNnSEheSAg", "_u2yEADIEEdqwaNnSEheSAg", "_yd3EzdnmEdmO6L4XMImrsA", "5.312818155786224E-305"]}];
					contentPage.preload(imgPath, backPath, nodeInfo,  '', false, false, false);
				</script>
</head>
<body>
<div id="breadcrumbs"></div>
<table width="100%" cellspacing="0" cellpadding="0" border="0">
<tr>
<td valign="top"><a name="Top"></a>
<div id="page-guid" value="5.312818155786224E-305"></div>
<table width="100%" cellpadding="0" cellspacing="0" border="0">
<tr>
<td nowrap="true" class="pageTitle">Концепция: Ключевые характеристики тестов</td><td width="100%">
<div id="contentPageToolbar" align="right"></div>
</td>
</tr>
</table>
<table cellspacing="0" cellpadding="0" border="0" width="100%">
<tr>
<td class="pageTitleSeparator"><img height="1" title="" alt="" src="./../../../images/shim.gif"></td>
</tr>
</table>
<div class="overview">
<table cellpadding="0" cellspacing="0" border="0" width="97%">
<tr>
<td width="50"><img title="" alt="" src="./../../../images/concept.gif"></td><td>
<table cellpadding="0" cellspacing="0" border="0" class="overviewTable">
<tr>
<td valign="top">В этом разделе обсуждаются охват и качество тестов.</td>
</tr>
</table>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Взаимосвязи</div>
<div class="sectionContent">
<table cellpadding="0" cellspacing="0" border="0" class="sectionTable">
<tr valign="top">
<th scope="row" class="sectionTableHeading">Связанные элементы</th><td class="sectionTableCell">
<ul>
<li>
<a href="./../../../core.base_rup/capabilitypatterns/define_evaluation_mission_DD06E225.html" guid="_6Bt54CGGEdqMcovRzkCQow">Определение задачи оценки</a>
</li>
<li>
<a href="./../../../core.base_rup/capabilitypatterns/define_evaluation_mission_611C79D9.html" guid="{10C2C34C-BF5E-4825-A7DC-5E106EFAA4C5}">Определение цели оценки</a>
</li>
<li>
<a href="./../../../core.base_rup/capabilitypatterns/achieve_acceptable_mission_18DE9944.html" guid="{5DA9C9E9-1538-4433-8B57-B28667D67514}">Получение приемлемой цели</a>
</li>
<li>
<a href="./../../../core.base_rup/capabilitypatterns/achieve_acceptable_mission_B27A73B1.html" guid="_D1WfBkdWEdqMoerwwyqMKQ">Получение приемлемой цели</a>
</li>
<li>
<a href="./../../../core.base_rup/workproducts/rup_test_evaluation_summary_D9B4016B.html" guid="{C6AAA2A6-C5AD-42DA-BCBC-9B1349D7B6CF}">Сводные результаты оценки тестирования</a>
</li>
<li>
<a href="./../../../core.base_rup/disciplines/rup_test_discipline_9DFAFB2F.html" guid="_yd3EzdnmEdmO6L4XMImrsA">Тестирование</a>
</li>
</ul>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Основное описание</div>
<div class="sectionContent">
<table cellpadding="0" cellspacing="0" border="0" class="sectionTable">
<tr valign="top">
<td class="sectionTableSingleCell"><a id="Top" name="Top"></a><a id="XE_test__key_measures_of" name="XE_test__key_measures_of"></a><a id="XE_measures__key_measures_of_test" name="XE_measures__key_measures_of_test"></a> 
<h3>
    <b><a id="Introduction" name="Introduction">Введение</a></b>
</h3>
<p>
    Ключевые характеристики тестов - охват и качество.
</p>
<p>
    Охват характеризует полноту теста и выражается в том, в каком объеме охвачены требования к тестированию или исполняемый
    код.
</p>
<p>
    Качество характеризует надежность, стабильность и производительность объекта тестирования (системы или приложения). Для
    оценки качества анализируются результаты тестирования и ошибки, обнаруженные при выполнении тестов.
</p>
<h3>
    <a id="XE_measures__types_of_test_coverage" name="XE_measures__types_of_test_coverage"></a><b><a id="Coverage" name="Coverage">Измерение охвата</a></b>
</h3>
<p>
    Измерив охват тестирования, можно ответить на следующий вопрос: "Насколько полно проведено тестирование?" Наиболее
    распространенные методы измерения охвата оперируют охватом требований к программному обеспечению и охватом исходного
    кода. В целом охватом тестирования можно назвать любую величину, измеренную либо по отношению к требованиям (охват на
    основе требований), либо по отношению к критериям реализации (охват на основе кода). Например, можно проверить все
    варианты использования (охват требований) или все строки исходного кода (охват кода).
</p>
<p>
    Все систематизированные методики тестирования основаны на той или иной стратегии охвата. В стратегии охвата
    сформулирована цель тестирования, и поэтому от нее напрямую зависит создание тестов. Формулировка стратегии охвата
    может быть очень простой, например: "Проверить все функции".
</p>
<p>
    Охвата требований может быть достаточно для количественного измерения полноты тестирования в случае, если полностью
    описаны все требования к системе. Например, если определены все требования к тестированию производительности, можно
    говорить о их количественном охвате: проверено 75% требований к тестированию производительности.
</p>
<p>
    Если применяется охват по коду, стратегии тестирования формулируются в терминах объема исходного кода, выполненного в
    ходе тестирования. Подобные стратегии тестирования очень важны для систем безопасности.
</p>
<p>
    Оба измерения можно проводить вручную (с помощью уравнений, приведенных в следующих разделах) или с помощью
    инструментов автоматизации тестирования.
</p>
<h4>
    <a id="Requirements-based test coverage" name="Requirements-based test coverage">Охват на основе требований</a>
</h4>
<p>
    Многократное измерение охвата требований в ходе цикла тестирования позволяет сделать охват одной из вех жизненного
    цикла, например, при оценке запланированного, реализованного, выполненного и завершенного тестирования.
</p>
<ul>
    <li>
        Охват измеряется с помощью следующего уравнения:
    </li>
</ul>
<blockquote>
    <p class="example">
        Охват = T<sup><sup>(p,i,x,s)</sup></sup> / RfT<br />
        <br />
         Где:<br />
         T - количество тестов (запланированных, реализованных, выполненных или завершенных). Это может быть количество
        процедур или тестовых наборов.
    </p>
    <p class="example">
        RfT - общее количество требований для тестирования.
    </p>
</blockquote>
<ul>
    <li>
        При выполнении задачи Планирование тестирования планируемый охват тестирования вычисляется по следующей формуле:
    </li>
</ul>
<blockquote>
    <p class="example">
        Охват тестирования (планируемый) = T<sup><sup>p</sup></sup> / RfT<br />
        <br />
         Где:<br />
         T<sup><sup>p</sup></sup> - количество запланированных тестов (процедур или тестовых наборов).
    </p>
    <p class="example">
        RfT - общее количество требований для тестирования.
    </p>
</blockquote>
<ul>
    <li>
        В задаче Реализовать тест, заключающейся в реализации процедур тестирования (в форме сценариев) охват вычисляется
        по следующей формуле:
    </li>
</ul>
<blockquote>
    <p class="example">
        Охват тестирования (реализованный) = T<sup><sup>i</sup></sup> / RfT<br />
        <br />
         где:<br />
         T<sup><sup>i</sup></sup> - количество реализованных тестов в виде количества процедур или тестовых наборов, для
        которых готовы сценарии.
    </p>
    <p class="example">
        RfT - общее количество требований для тестирования.
    </p>
</blockquote>
<ul>
    <li>
        На этапе выполнения тестов применяются два показателя: количество выполненных тестов и количество тестов,
        выполненных успешно (завершенных тестов, при выполнении которых не возникло ошибок и не были получены
        непредусмотренные результаты). 
        <p>
            Охват вычисляется с помощью следующих формул:
        </p>
        <blockquote>
            <p class="example">
                Охват тестирования (выполненный) = T<sup><sup>x</sup></sup> / RfT
            </p>
        </blockquote>
        <blockquote>
            <p class="example">
                Где:<br />
                 T<sup><sup>x</sup></sup> - количество выполненных тестов в форме числа процедур или тестовых наборов.
            </p>
        </blockquote>
        <blockquote>
            <p class="example">
                RfT - общее количество требований для тестирования.
            </p>
        </blockquote>
    </li>
    <li style="LIST-STYLE-TYPE: none">
        <br />
        <br />
    </li>
</ul>
<blockquote>
    <p class="example">
        Охват тестирования (завершенный) = T<sup><sup>s</sup></sup> / RfT
    </p>
    <blockquote>
        <p class="example">
            Где:<br />
             T<sup><sup>s</sup></sup> - количество успешно завершенных процедур или тестовых наборов.
        </p>
    </blockquote>
    <blockquote>
        <p class="example">
            RfT - общее количество требований для тестирования.
        </p>
    </blockquote>
</blockquote>
<div style="MARGIN-LEFT: 4em">
    <br />
    <br />
</div>
<p>
    Выразив эти значения в процентах, можно получить следующую форму для оценки охвата тестирования:
</p>
<blockquote>
    <p>
        x% тестов (T<sup><sup>(p,i,x,s)</sup></sup> в формулах, приведенных выше) охвачено с процентом успеха y%
    </p>
</blockquote>
<p>
    Эту количественную оценку охвата тестирования можно сравнить с предопределенными критериями. Если критерии не
    выполнены, появляется возможность оценить, сколько еще тестирования потребуется.
</p>
<h4>
    <a id="Code-based test coverage" name="Code-based test coverage">Охват на основе кода</a>
</h4>
<p>
    Стратегия охвата на основе кода предполагает измерение количества кода, выполненного во время тестирования, и сравнение
    полученного значения с объемом кода, подлежащего выполнению. Количество кода можно измерять с помощью потоков
    управления (операторы, ветви и пути) и потоков данных.
</p>
<ul>
    <li>
        Если для измерения применяются потоки управления, цель тестирования формулируется в виде выполнения определенного
        количества строк кода, условий ветвления, путей выполнения кода или других элементов потоков управления.
    </li>
    <li>
        Если для измерения применяются потоки данных, цель тестирования формулируется в виде проверки сохранения
        целостности данных в ходе работы программного обеспечения - например, проверке того, что объекты данных создаются
        перед первым использованием.
    </li>
</ul>
<p>
    Охват кода измеряется по следующей формуле:
</p>
<blockquote>
    <p class="example">
        Охват = I<sup><sup>e</sup></sup> / TIic
    </p>
</blockquote>
<blockquote>
    <p class="example">
        Где:<br />
         I<sup><sup>e</sup></sup> - количество выполненных элементов (операторов, ветвей, путей, точек принятия решений или
        имен элементов данных).
    </p>
</blockquote>
<blockquote>
    <p class="example">
        TIic - общее количество элементов кода.
    </p>
</blockquote><br />
<br />
<p>
    Выразив это значение в процентах, можно получить следующую оценку для охвата тестирования по коду:
</p>
<blockquote>
    <p>
        x% тестов (I в формуле выше) охвачено с процентом успеха y%
    </p>
</blockquote>
<p>
    Эту количественную оценку охвата тестирования можно сравнить с предопределенными критериями. Если критерии не
    выполнены, появляется возможность оценить, сколько еще тестирования потребуется.
</p>
<h3>
    <a id="XE_measures__for_perceived_quality" name="XE_measures__for_perceived_quality"></a><b><a id="Quality" name="Quality">Измерение качества</a></b>
</h3>
<p>
    Хотя оценка охвата тестирования позволяет получить представление о полноте теста, качество программного обеспечения
    удобнее оценивать путем анализа ошибок, обнаруженных в ходе тестирования. Полученная таким способом оценка качества
    характеризует качество программной системы в целом. Измеренное качество программного обеспечения - это величина,
    показывающая, насколько программное обеспечение соответствует предъявляемым к нему требованиям. Поэтому в данном
    контексте ошибки рассматриваются как особый тип запросов изменений, в которых объект тестирования не соответствовал
    требованиям к программному обеспечению.
</p>
<p>
    Для оценки ошибок могут применяться разнообразные методы - от простого подсчета количества до сложного статистического
    моделирования.
</p>
<p>
    В хорошей процедуре оценки должны применяться предположения относительно частоты обнаружения ошибок в ходе
    тестирования. Как правило, частоту обнаружения ошибок характеризуют распределением Пуассона. Фактические данные затем
    подставляются в эту модель. Полученная оценка позволяет судить о текущей надежности программного обеспечения и
    прогнозировать рост надежности по мере продолжения тестирования и исправления ошибок. Подобную оценку обычно называют
    моделированием роста надежности программного обеспечения, и в настоящее время ведутся интенсивные исследования в данной
    области. В силу отсутствия инструментов для проведения подобных оценок рекомендуется сопоставить стоимость применения
    данного подхода с преимуществами, которые можно получить от его применения.
</p>
<p>
    <b>Анализ ошибок</b> - эта стратегия заключается в изучении распределения ошибок по разным атрибутам, связанным с ними.
    Результаты анализа ошибок позволяют судить о надежности программного обеспечения.
</p>
<p>
    Стратегия анализа ошибок обычно оперирует четырьмя атрибутами:
</p>
<ul>
    <li>
        <b>состояние</b> - текущее состояние ошибки (открыта, исправляется, исправлена и т.п.)
    </li>
    <li>
        <b>приоритет</b> - относительная важность исправления данной ошибки
    </li>
    <li>
        <b>серьезность</b> - относительная степень воздействия данной ошибки на пользователя, организацию, сторонних лиц и
        т.д.
    </li>
    <li>
        <b>источник</b> - где находится причина ошибки, какова эта причина, какой компонент потребуется исправить для
        устранения ошибки.
    </li>
</ul>
<p>
    Если рассматривать количество ошибок как функцию времени, можно строить диаграммы и графики изменения количества
    ошибок. Можно создавать отчеты о плотности ошибок и их распределении по значениям атрибутов, например серьезности и
    состоянию. Подобные виды анализа позволяют получить представление о динамике обнаружения и исправления ошибок и, как
    следствие, о надежности программного обеспечения.<br />
    <br />
     Например, предполагается, что по мере тестирования и исправления ошибок должна снижаться частота их обнаружения. Можно
    установить порог низкого качества, по достижении которого качество программного продукта будет признаваться
    неприемлемым. Кроме того, можно создавать отчеты о количестве ошибок определенного происхождения и выявлять "слабые
    модули", "горячие точки" и компоненты программного обеспечения, которые постоянно нуждаются в исправлении ошибок.
    Наличие таких компонентов служит признаком фундаментальных ошибок при их проектировании.
</p>
<p>
    В подобных видах анализа должны учитываться только подтвержденные ошибки. Не все обнаруженные ошибки в действительности
    являются ошибками - часть из них представляет собой требования расширить набор функций системы, часть - повторные
    отчеты об уже обнаруженных ошибках. Тем не менее, никогда не помешает узнать, какое количество ошибок регистрируется в
    качестве повторных, а какое - не подтверждается.
</p>
<h4>
    <a id="Defect Reports" name="Defect Reports">Отчеты об ошибках</a>
</h4>
<p>
    В Rational Unified Process рекомендовано оценивать ошибки по нескольким категориям:
</p>
<ul>
    <li>
        Отчеты о распределении (плотности) ошибок показывают количество ошибок как функцию одного или двух атрибутов.
    </li>
    <li>
        Отчеты о давности ошибок представляют собой особую разновидность отчетов о распределении. В отчетах о давности
        содержится информация о том, как долго ошибки находятся в определенных состояниях (например, "открыта"). В каждой
        категории ошибки можно сортировать по другим атрибутам, например по владельцу.
    </li>
    <li>
        В отчетах о тенденциях показано распределение ошибок по состояниям (новая, открыта или закрыта) в виде функции
        времени. Можно рассматривать как тенденции по отдельным атрибутам, так и общие тенденции.
    </li>
</ul>
<p>
    Многие из этих отчетов полезны при оценке качества программного обеспечения. Максимальную пользу они приносят в
    сочетании с отчетами о ходе и результатах тестирования, в которых приведены данные о количестве тестов, выполненных на
    различных итерациях и циклах тестирования приложения. В число стандартных условий тестирования входит ограничение на
    количество открытых ошибок определенных категорий (например, определенной серьезности), что очень легко проверить по
    отчетам о распределении ошибок. Отсортировав или сгруппировав распределение по нужным признакам, можно сфокусироваться
    на важнейших тенденциях.
</p>
<p>
    Как правило, для создания подобных отчетов требуются специализированные инструменты.
</p>
<h4>
    <b><a id="Defect density reports:" name="Defect density reports:">Отчеты о плотности ошибок</a></b>
</h4>
<h5>
    <b>Состояние и приоритеты ошибок</b>
</h5>
<p>
    Рекомендуется присваивать приоритеты всем ошибкам. Обычно достаточно четырех приоритетов:
</p>
<ul>
    <li>
        высочайший приоритет (требуется незамедлительное исправление)
    </li>
    <li>
        высокий приоритет
    </li>
    <li>
        обычный приоритет
    </li>
    <li>
        низкий приоритет
    </li>
</ul>
<p>
    <b>Примечание</b>: критерии успешного тестирования можно выразить в форме целевого распределения ошибок по приоритетам.
    Например, тестирование можно считать успешным, если нет ошибок приоритета 1 и открыто меньше пяти ошибок приоритета 2.
    Рекомендуется создать диаграмму распределения ошибок, как показано на следующей иллюстрации.
</p>
<p align="center">
    <img height="233" alt="Диаграмма распределения ошибок" src="./../../../core.base_rup/guidances/concepts/resources/keymeas1.gif" width="378" />
</p><br />
<br />
<p>
    В данном случае очевидно, что условия не выполнены. На диаграмме нужно включить фильтр, чтобы были показаны только
    открытые ошибки.
</p>
<h5>
    <b>Состояние и серьезность ошибок</b>
</h5>
<p>
    В отчетах о серьезности указано распределение ошибок по серьезности (например, отказ системы, недоступность важной
    функции, незначительное неудобство).
</p>
<h5>
    <b>Состояние ошибок и их расположение в модели реализации</b>
</h5>
<p>
    В этом отчете показано распределение ошибок по элементам модели реализации.
</p>
<h4>
    <b><a id="Defect aging reports:" name="Defect aging reports:">Отчеты о давности ошибок</a></b>
</h4>
<p>
    Анализ давности ошибок позволяет получить хорошее представление об эффективности тестирования и устранения ошибок.
    Например, если большинство давних неисправленных ошибок находятся в состоянии ожидания подтверждения исправления,
    вероятно, недостаточно внимания уделяется повторному тестированию.
</p>
<h4>
    <b><a id="Defect trend reports:" name="Defect trend reports:">Отчеты о тенденциях распределения ошибок</a></b>
</h4>
<p>
    Отчеты о тенденциях распределения ошибок дают очень хорошую видимость состояния процесса тестирования. В ходе цикла
    тестирования тенденции проходят несколько хорошо предсказуемых стадий. На начальном этапе резко возрастает количество
    обнаруженных ошибок, которое в какой-то момент достигает пика, а затем начинает медленно снижаться.
</p><br />
<br />
<p align="center">
    <img height="230" alt="Диаграмма тенденции распределения ошибок" src="./../../../core.base_rup/guidances/concepts/resources/keymeas2.gif" width="373" />
</p>
<p>
    Данную тенденцию можно сопоставить с графиком проекта. Если на в течение третьей недели четырехнедельного цикла
    тестирования по-прежнему растет количество обнаруживаемых ошибок, проект совершенно точно выбивается из графика.
</p>
<p>
    При таком прямолинейном анализе тенденций предполагается, что ошибки исправляются быстро, и что исправления проверяются
    в очередных компиляциях продукта, то есть, тенденция закрытия ошибок должна развиваться примерно так же, как тенденция
    из обнаружения. Если это не так, скорее всего, что-то происходит не по плану на этапе устранения ошибок, либо
    недостаточно ресурсов для повторного тестирования и проверки исправления ошибок.
</p>
<p align="center">
    <img height="230" alt="Диаграмма отчета об анализе тенденций" src="./../../../core.base_rup/guidances/concepts/resources/keymeas3.gif" width="469" />
</p>
<p>
    На этой диаграмме хорошо видна тенденция - сначала обнаружено много ошибок, а затем, со временем, их находят все меньше
    и меньше. Тенденция количества открытых ошибок повторяет тенденцию обнаружения ошибок с небольшим запозданием.
    Тенденция количества закрытых ошибок развивается со временем по мере исправления и проверки обнаруженных ошибок.
    Подобная картина свидетельствует об успешном тестировании.
</p>
<p>
    Если в вашей среде тенденции существенно отличаются от показанных на этой диаграмме, можно предположить, что вам
    требуются дополнительные ресурсы в определенных областях разработки или тестирования.
</p>
<p>
    Как и охват тестирования, анализ ошибок представляет собой отличную базу для формулировки критериев оценки
    тестирования.
</p>
<h3>
    <a id="Performance" name="Performance">Показатели производительности</a>
</h3>
<p>
    Для оценки производительности объекта тестирования и сбора данных о его поведении, включая время отклика,
    продолжительность выполнения операций, стабильность и ограничения, применяются несколько показателей. В основном эти
    показатели оцениваются в ходе выполнении задачи Оценка тестирования, однако некоторые из них используются в задаче
    Выполнить тесты для оценки хода выполнения и состояния тестирования.
</p>
<p>
    Основные показатели производительности:
</p>
<ul>
    <li>
        <b>Динамический мониторинг</b> - анализ состояния сценариев тестирования в реальном времени в ходе выполнения
        тестов.
    </li>
    <li>
        <b>Отчеты о пропускной способности и времени отклика</b> - измерение времени отклика и пропускной способности
        объекта тестирования по субъектам и вариантам использования.
    </li>
    <li>
        <b>Процентные отчеты</b> - процентные показатели сбора данных.
    </li>
    <li>
        <b>Сравнительные отчеты</b> - в этих отчетах показана разность тенденций нескольких наборов данных, отражающих
        выполнение различных тестов.
    </li>
    <li>
        <b>Трассировочные отчеты</b> - подробные сведения о сообщениях и диалогах между субъектами (сценариями
        тестирования) и объектом тестирования.
    </li>
</ul>
<h4>
    <a id="Dynamic Monitoring" name="Dynamic Monitoring">Динамический мониторинг</a>
</h4>
<p>
    Динамический мониторинг применяется для просмотра данных о тестировании в реальном времени, обычно в форме гистограмм и
    графиков. В данных отчетах приводятся такие данные, как текущее состояние и ход выполнения сценариев тестирования.
</p>
<p align="center">
    <img height="333" alt="Гистограмма динамического мониторинга" src="./../../../core.base_rup/guidances/concepts/resources/keymeas4.gif" width="501" />
</p>
<p>
    Например, на гистограмме выше показаны 80 сценариев, выполняющих один и тот же вариант использования. В состоянии Idle
    (простой) находятся 14 сценариев, в состоянии Query (запрос) - 12, SQL Execution (выполнение SQL) - 34, SQL Connect
    (установка соединения SQL) - 4 и Other (прочие состояния) - 16. В ходе тестирования распределение тестов по состояниям
    будет меняться. Приведенная выше гистограмма характерна для нормального хода тестирования приблизительно в середине
    теста. Если в ходе тестирования сценарии остаются в одном и том же состоянии, скорее всего, при выполнении теста
    возникла ошибка, либо требуется скорректировать методику измерения производительности.
</p>
<h4>
    <a id="Response time and throughput reports" name="Response time and throughput reports">Отчеты о пропускной
    способности и времени отклика</a>
</h4>
<p>
    В этих отчетах приводятся данные о времени отклика и пропускной способности (количестве выполненных транзакций) объекта
    тестирования. Как правило, эти отчеты представляют собой графики с временем отклика (или пропускной способностью) на
    оси Y и количеством событий на оси Х.
</p>
<p align="center">
    <img height="333" alt="Пример отчета о пропускной способности" src="./../../../core.base_rup/guidances/concepts/resources/keymeas5.gif" width="499" />
</p>
<p>
    Иногда возникает потребность в просмотре и вычислении статистических показателей, например стандартного отклонения, в
    дополнение к непосредственным показателям производительности.
</p>
<h4>
    <a id="Percentile Reports" name="Percentile Reports">Процентные отчеты</a>
</h4>
<p>
    Процентные отчеты представляют собой отдельную разновидность отчетов, в которых показано процентное распределение
    собранных данных.
</p>
<p align="center">
    <img height="333" alt="Пример диаграммы процентного отчета" src="./../../../core.base_rup/guidances/concepts/resources/keymeas6.gif" width="499" />
</p>
<h4>
    <a id="Comparison Reports" name="Comparison Reports">Сравнительные отчеты</a>
</h4>
<p>
    Сравнение результатов выполнения различных тестов производительности позволяет оценить влияние изменений, внесенных
    между выполнением тестов, на производительность объекта тестирования. Для сравнения двух наборов данных
    (соответствующих различным выполнениям теста) и анализа изменений применяются сравнительные отчеты.
</p>
<h4>
    <a id="Trace and Profile Reports" name="Trace and Profile Reports">Трассировочные отчеты</a>
</h4>
<p>
    Если объект тестирования демонстрирует неприемлемую производительность, либо если мониторинг свидетельствует о
    возникновении узких мест (например, когда сценарии тестирования в течении длительного времени остаются в каком-либо
    определенном состоянии), лучшим средством диагностики могут стать трассировочные отчеты. В трассировочных отчетах
    содержится низкоуровневая информация. В частности, в этих отчетах приведены сообщения, которыми субъект обменивается с
    объектом тестирования, поток выполнения, операции обращения к данным, сведения о вызовах функций и системных вызовах.
</p><br />
<br /></td>
</tr>
</table>
</div>
<table cellpadding="0" cellspacing="0" border="0" class="copyright">
<tr>
<td class="copyright"><p>
    &copy; &nbsp;Copyright IBM Corp.&nbsp;1987, 2006. &nbsp;Все права защищены..
</p></td>
</tr>
</table>
</td>
</tr>
</table>
</body>
<script language="JavaScript" type="text/javascript">
				contentPage.onload();
			</script>
</html>
